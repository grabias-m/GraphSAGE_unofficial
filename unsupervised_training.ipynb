{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from graphsage.model import load_cora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import init\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "from sklearn.metrics import f1_score\n",
    "from collections import defaultdict\n",
    "\n",
    "from graphsage.encoders import Encoder\n",
    "from graphsage.aggregators import MeanAggregator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class UnsupervisedGraphSage(nn.Module):\n",
    "\n",
    "    def __init__(self, enc, degree_list):\n",
    "        super(UnsupervisedGraphSage, self).__init__()\n",
    "        self.enc = enc\n",
    "        self.xent = nn.BCELoss()\n",
    "        wt = np.power(degree_list, 0.75)\n",
    "        wt = wt / wt.sum()\n",
    "        self.weights = torch.FloatTensor(wt)\n",
    "        \n",
    "    def negative_sample(self, number_of_neg_sample):\n",
    "        return torch.multinomial(self.weights, number_of_neg_sample, \n",
    "                                 replacement=True)\n",
    "\n",
    "    def forward(self, nodes):\n",
    "        embeds = self.enc(nodes)\n",
    "        return embeds\n",
    "    \n",
    "    def affinity(self, input_1, input_2):\n",
    "        output_1 = torch.nn.functional.normalize(self.forward(input_1))\n",
    "        output_2 = torch.nn.functional.normalize(self.forward(input_2))\n",
    "        aff = torch.sum((output_1 * output_2), dim=1)\n",
    "        \n",
    "        return output_1, aff\n",
    "    \n",
    "    def neg_affinity(self, output_1, neg_samples):\n",
    "        neg_output = torch.nn.functional.normalize(self.forward(neg_samples))\n",
    "        neg_aff = torch.mm(output_1.t(),neg_output)\n",
    "        \n",
    "        return neg_aff\n",
    "\n",
    "    def loss(self, edges, neg_samples):\n",
    "        input_1 = [edge[0] for edge in edges]\n",
    "        input_2 = [edge[1] for edge in edges]\n",
    "        \n",
    "        output_1, aff = self.affinity(input_1, input_2)\n",
    "        neg_aff = self.neg_affinity(output_1, neg_samples)\n",
    "        \n",
    "        total_loss = 0\n",
    "        total_loss += - torch.sum(torch.log(torch.sigmoid(aff)))\n",
    "        total_loss += - len(neg_samples) * torch.sum((torch.log(torch.sigmoid(-neg_aff))))\n",
    "        \n",
    "        return total_loss\n",
    "    \n",
    "    def compare_loss(self, edges):\n",
    "        input_1 = [edge[0] for edge in edges]\n",
    "        input_2 = [edge[1] for edge in edges]\n",
    "        \n",
    "        _, aff = self.affinity(input_1, input_2)\n",
    "        total_loss = - torch.mean(torch.log(torch.sigmoid(aff)))\n",
    "        \n",
    "        return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes = 2708\n",
    "feat_data, labels, adj_lists = load_cora()\n",
    "features = nn.Embedding(2708, 1433)\n",
    "features.weight = nn.Parameter(torch.FloatTensor(feat_data), requires_grad=False)\n",
    "agg1 = MeanAggregator(features, cuda=True)\n",
    "enc1 = Encoder(features, 1433, 128, adj_lists, agg1, gcn=True, cuda=False)\n",
    "agg2 = MeanAggregator(lambda nodes : enc1(nodes).t(), cuda=False)\n",
    "enc2 = Encoder(lambda nodes : enc1(nodes).t(), enc1.embed_dim, 128, adj_lists, agg2,\n",
    "            base_model=enc1, gcn=True, cuda=False)\n",
    "enc1.num_samples = 5\n",
    "enc2.num_samples = 5\n",
    "rand_indices = np.random.permutation(num_nodes)\n",
    "test = rand_indices[:1000]\n",
    "val = rand_indices[1000:1500]\n",
    "train = list(rand_indices[1500:])\n",
    "train_degree_list = [len(adj_lists[node]) for node in train]\n",
    "train_edges = [(row, node) for row in train for node in adj_lists[row] if node in train]\n",
    "val_edges = [(row, node) for row in val for node in adj_lists[row] if node not in test]\n",
    "graphsage = UnsupervisedGraphSage(enc2, train_degree_list)\n",
    "optimizer = torch.optim.Adam(filter(lambda p : p.requires_grad, graphsage.parameters()), lr=0.0001)\n",
    "batch_size = 30\n",
    "number_of_neg_sample = 20\n",
    "times = []\n",
    "for batch in range(1000):\n",
    "    batch_edges = train_edges[:batch_size]\n",
    "    neg_samples = graphsage.negative_sample(number_of_neg_sample)\n",
    "    random.shuffle(train_edges)\n",
    "    start_time = time.time()\n",
    "    optimizer.zero_grad()\n",
    "    loss = graphsage.loss(batch_edges, neg_samples)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    end_time = time.time()\n",
    "    times.append(end_time-start_time)\n",
    "    if batch % 20 == 0:\n",
    "        loss_train =  graphsage.compare_loss(train_edges)\n",
    "        loss_val = graphsage.compare_loss(val_edges)\n",
    "        print(batch, loss.data, loss_train.data, loss_val.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val = rand_indices[1000:1500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_edges = [(row, node) for row in val for node in adj_lists[row] if node not in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "77845d2f7d5fa83174d5cbd19bb448ec4c04be8e20fe1d69a90ac8ab1cfaea9e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
